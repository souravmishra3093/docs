---
title: "Speech-to-Text (Streaming)"
description: "An introduction to getting transcription data from live streaming audio in real time."
---

### Getting Started

In this guide, you’ll learn how to automatically transcribe live streaming audio in real time using Reverie's SDKs, which are supported for use with the Reverie API.

<Note>
  Before you start, you'll need to follow the steps in the [Get your API
  Credentials](/authentication) to obtain your API key.
</Note>

### Include the SDK

To use Reverie's Speech-to-Text Streaming SDK, include the following CDN in your project:

```html
<!-- If you are using STT stream, add the following script to the head section of your index.html -->
<script src="https://cdn.jsdelivr.net/npm/reverie-stt-sdk/dist/bundle.js"></script>
```

### Install Dependencies

<CodeGroup>

```bash JavaScript
npm i @reverieit/reverie-client
```

```bash Python
pip install reverie-sdk
pip install pyaudio
```

</CodeGroup>
### Transcribe Audio from a Remote Stream

The following code shows how to transcribe audio from a remote audio stream. If you would like to learn how to stream audio from a microphone.

<CodeGroup>
```javascript Javascript
const ReverieClient = require("reverie-client");

const reverieClient = new ReverieClient({
apiKey: "YOUR-API-KEY",
appId: "YOUR-APP-ID",
});

await reverieClient.init_stt({
src_lang: "hi",
callback: (event) => {
console.log("STT event:", event);
},
element: document.getElementById("transcript"),
domain: "generic"

});

// Start/Stop streaming
await reverieClient.start_stt();
await reverieClient.stop_stt();

````

```python Python
import pyaudio, asyncio
from reverie_sdk import ReverieClient, AudioStream

client = ReverieClient(
    api_key="<YOUR-API-KEY>",
    app_id="<YOUR-APP-ID>",
)

stream = AudioStream()
pa = pyaudio.PyAudio()

def mic_callback(in_data, frame_count, time_info, status):
    try:
        asyncio.run(stream.add_chunk_async(in_data))
    except:
        return (None, pyaudio.paAbort)
    return (None, pyaudio.paContinue)

async def main():
    pa_stream = pa.open(
        rate=16000,
        channels=1,
        format=pyaudio.paInt16,
        frames_per_buffer=1024,
        input=True,
        stream_callback=mic_callback,
    )
    pa_stream.start_stream()

    print("listening... press ctrl+C to stop", flush=True)

    try:
        await client.asr.stt_stream_async(
            src_lang="en",  # Language code
            bytes_or_stream=stream,
            callback=print,  # Handle transcription results
        )
    except Exception as err:
        print(err)
    finally:
        pa_stream.stop_stream()
        pa_stream.close()

asyncio.run(main())
pa.terminate()
````

</CodeGroup>

<Note>
The above example includes the parameter model=nova-3, which tells the API to use Deepgram’s latest model. Removing this parameter will result in the API using the default model, which is currently model=base.

It also includes Deepgram’s Smart Formatting feature, smart_format=true. This will format currency amounts, phone numbers, email addresses, and more for enhanced transcript readability.

</Note>

### Results

In order to see the results from Reverie, you must run the application. Run your application from the terminal. Your transcripts will appear in your shell.

<CodeGroup>

```bash JavaScript
# Run your application using the file you created in the previous step
# Example:
npm start
```

```python Python
# Run your application using the file you created in the previous step
# Example:
python main.py
```

```go GoLang
// Run your application using the file you created in the previous step
// Example:
go run main.go
```

</CodeGroup>

### Analyzing the Response

```json
{
  "id": "bb261bd789af4ba487a2667f8d942d4d7e0195fd1c8e4073",
  "success": true,
  "text": "आत्म निर्भर योजना इस योजना अथवा अभियान का उद्देश्य एक सौ तीस करोड़ भारतवासियों को आत्मनिर्भर बनाना है ताकि देश का हर नागरिक संकट की इस घड़ी में कदम से कदम मिलाकर चल सके",
  "display_text": "आत्म निर्भर योजना इस योजना अथवा अभियान का उद्देश्य 130 करोड़ भारतवासियों को आत्मनिर्भर बनाना है",
  "final": true,
  "confidence": 0.743304,
  "cause": "EOF received"
}
```

In this response we see:

- `id` : API will auto-assign assign a unique identification number for each request.
- `success` : Will indicate the functional status of the API:
  - If the `success` = true, then the API is functioning and ready to generate output.
  - If the `success` = false, then the API is not functional and has some errors
- `final` : Will report whether the received output is partial or final:
  - If the `final` = true, then the received text is the final output.
  - If the `final` = false, then the text received is partial and is still processing the file.
- `cause` : Reason for obtaining the final output.
- `text` : The streaming audio input is converted into text format in the requested language.
- `confidence` : The level of confidence that Streaming STT API has in the accuracy of the transcription.
- `display_text` : The beautified text of the final transcript. If the final transcript consists of digits, URL, app names, it is quickly converted to a readable format for the user.

### Key Features

<CardGroup cols={2}>
  <Card title="Real-time Transcription" icon="microphone">
    Transcribe pre-recorded audio into text with high accuracy in real-time,
    even from lower-quality inputs.
  </Card>
  <Card title="Personalized Speech Model" icon="microphone">
    Customize recognition for domain-specific terms to boost accuracy of unique
    words or phrases.
  </Card>
  <Card title="Noise Resistance" icon="play">
    Decode moderately noisy audio from various environments without extra noise
    cancellation.
  </Card>
  <Card title="Content Filtering" icon="filter">
    Filter out inappropriate content with an obscenity detector for clean text
    output.
  </Card>
</CardGroup>
<CardGroup cols={2}>
  <Card title="Cloud-based Deployment" icon="cloud">
    Scalable and accessible from anywhere for dynamic, distributed teams.
  </Card>
  <Card title="On-premise Deployment" icon="server">
    Secure and customizable to integrate with your existing infrastructure.
  </Card>
</CardGroup>

### Sample Code

<CardGroup cols={2}>
  <a
    href="https://github.com/reverieinc/python-sdk/tree/main/stt-stream"
    target="_blank"
    rel="noopener noreferrer"
  >
    <Card title="Python" icon="python">
      Access Python SDK samples for real-time speech transcription on GitHub
    </Card>
  </a>

{" "}

<a
  href="https://github.com/reverieinc/javascript-sdk/tree/main/stt-stream"
  target="_blank"
  rel="noopener noreferrer"
>
  <Card title="JavaScript" icon="js">
    Explore JavaScript SDK samples for speech-to-text streaming on GitHub
  </Card>
</a>

  <a
    href="https://github.com/reverieinc/golang-sdk/tree/main/stt-stream"
    target="_blank"
    rel="noopener noreferrer"
  >
    <Card title="GoLang" icon="golang">
      Find GoLang SDK samples for speech transcription on GitHub
    </Card>
  </a>
</CardGroup>

### FAQs

<AccordionGroup>
  <Accordion
    title="What is the accuracy of real-time transcription?"
    icon="chart-line"
  >
    The solution delivers **high accuracy**, even with lower-quality audio,
    thanks to: - Robust speech decoding technology - Built-in noise resistance
    for reliable performance
  </Accordion>
  <Accordion
    title="Can I customize the speech model for my industry?"
    icon="sliders"
  >
    **Yes**, the Personalized Speech Model feature lets you: - Tailor
    recognition to domain-specific terms - Boost accuracy for unique words or
    phrases specific to your use case
  </Accordion>
  <Accordion title="Does it work in noisy environments?" icon="play">
    **Absolutely**, the Noise Resistance feature ensures: - Decoding of moderate
    noise without extra cancellation - Consistent performance across diverse
    environments
  </Accordion>
  <Accordion title="How do I deploy the solution?" icon="rocket">
    It supports **flexible deployment** options: - *Cloud-based*: Scalable and
    accessible anywhere - *On-premise*: Secure and tailored to your
    infrastructure
  </Accordion>
  <Accordion title="Which domains are supported?" icon="list">
    Specialized models cover a wide range, including: - BFSI, Healthcare,
    E-commerce, and more - See the [Supported Domains](#supported-domains)
    section for details
  </Accordion>
</AccordionGroup>

### Supported Domains

| Domain       | Description                                                      |
| ------------ | ---------------------------------------------------------------- |
| generic      | Trained to transcribe speech across industries.                  |
| bfsi         | Optimized for banking and financial terminologies.               |
| ecomm   | Tailored for E-commerce and FMCG-specific terms.                 |
| healthcare   | Specialized in medical and healthcare terminology.               |
| voice-search | Handles voice commands with smart formatting for search.         |
| alphanumeric | Accurately transcribes mixed letters and numbers.                |
| names        | Trained to recognize and transcribe person names.                |
| address      | Optimized for transcribing address details.                      |
| language     | Supports regional language variants (e.g., 'Bengali', 'Bangla'). |
| yes-no       | Recognizes diverse yes/no responses (e.g., 'Haan', 'Yes').       |
| email        | Precisely transcribes email addresses.                           |

### Supported Languages

The Speech-to-Text solution supports transcription in multiple languages, tailored for diverse regional and linguistic needs:

- `hi` - Hindi
- `bn` - Bengali
- `gu` - Gujarati
- `kn` - Kannada
- `ml` - Malayalam
- `mr` - Marathi
- `pa` - Punjabi
- `ta` - Tamil
- `te` - Telugu
- `en` - Indian English
- `as` - Assamese
- `or` - Odia

### Supported Audio Formats

The Speech-to-Text solution supports various audio formats for flexible integration:

| Audio Format | Description                                                      |
| ------------ | ---------------------------------------------------------------- |
| 16k_int16    | Default format: Signed 16-bit, 16KHz sampling rate in WAV format |
| 16k_uint8    | Unsigned 8-bit, 16KHz sampling rate in WAV format                |
| 8k_int16     | Signed 16-bit, 8KHz sampling rate in WAV format                  |
| 8k_uint8     | Unsigned 8-bit, 8KHz sampling rate in WAV format                 |
| opus_16k     | Opus-encoded audio frames, 16KHz sampling rate                   |
| opus_8k      | Opus-encoded audio frames, 8KHz sampling rate                    |
| ogg_opus     | Opus-encoded audio frames in Ogg container                       |
| 16k_ulaw     | µ-Law audio frames, 16KHz sampling rate                          |
| 8k_ulaw      | µ-Law audio frames, 8KHz sampling rate                           |

### API Messages

| Message Code | Message              | Description                                                      |
|--------------|----------------------|------------------------------------------------------------------|
| 403          | Forbidden            | Entered Invalid credentials                                      |
| 403          | Forbidden            | The provided credit limit is exhausted.                          |
| 403          | Forbidden            | The API key provided to a user is expired.                       |
| 403          | Forbidden            | The user is not authorized to use the STT API.                   |
| 403          | Forbidden            | The invalid language code is passed, or the user has entered the code, which he is not authorized to use. |
| 400          | no decoder for given args | For the language and domain given in the request, STT service is not available |
| 200          | unsupported audio format | The API does not support the audio format.                       |
| 200          | ready                | STT is ready to receive audio data                               |
| 200          | partial              | This is a partial response. Keep waiting for the final response. |
| 200          | EOF received         | This is the final response. The connection will be closed as EOF received in the request. |
| 200          | silence detected     | This is the final response. The connection will be closed as silence is received in the request. |
| 200          | timeout              | This is the final response. The connection will be closed as no data is received. |
| 200          | audio too short      | Audio too short to detect transcription                          |
